
# 关联规则

## 基本概念

### 购物篮分析：啤酒与尿布的经典案例

关联规则挖掘的起源可追溯到20世纪90年代初，由IBM公司Almaden研究中心的Agrawal等人引入数据库社区。沃尔玛"啤酒与尿布"案例是最早的成功应用：发现购买尿布的男性顾客常常会顺便购买啤酒，于是将这两种商品摆放在相邻位置。广泛应用领域：购物篮分析、交叉销售、点击流分析、推荐系统、医疗诊断、通信、互联网、电子商务等。


### 关联规则的分类

关联规则可以分为以下几类：
+ 布尔型和数值型关联规则
+ 单层关联规则和多层关联规则
+ 单维关联规则和多维关联规则



**布尔型和数值型关联规则**看“变量取值类型”， 布尔型变量只有 出现 / 不出现（0/1），数值型变量往往需要区间化。

布尔型：买没买？
```
尿布 → 啤酒 
（布尔型关联规则）
```
数值型：买了多少 / 多大 / 多贵？
```
(年龄 ∈ [20,30]) ∧ (收入 > 8000) → (购买高端手机)   

（数值型关联规则）
```

**单层关联规则和多层关联规则**看“概念层次（是否用到概念层次树）”，单层关联规则所有项目在同一抽象层次，不用概念层次。多层关联规则使用概念层次（is-a），不同抽象层级同时出现。

单层：具体商品之间的关系
```
牛奶 → 面包 
```
多层：类别 ↔ 类别 / 类别 ↔ 商品
```
乳制品 → 烘焙食品
牛奶 → 面包
```
概念层次示意
```
食品
 ├─ 乳制品
 │   └─ 牛奶
 └─ 烘焙食品
     └─ 面包
```

**单维关联规则和多维关联规则**看“用了多少个属性（维度）”,单维关联规则只涉及一个维度,例如 “商品 ↔ 商品”，多维关联规则涉及多个属性，常见于用户画像分析。


单维：只看买了什么
```
{尿布} → {啤酒}
```
多维：谁在什么条件下买了什么
```
{年龄=20-30, 性别=男} → {购买=啤酒}
```





### 关联规则的概念（项集、支持度、置信度、提升度）
关联规则挖掘是指从一个大型的数据集（dataset）中发现有趣的关联或相关关系，即从数据集中识别出频繁出现的属性值集，也称为**频繁项集**，然后利用这些频繁项集创建描述关联关系规则的过程。关联规则相关定义如下：


**项集(itemset)**
   - 定义：I={i₁, i₂, ..., iₘ}是m个不同项目的集合，每个iⱼ称为项目，I称为项集
   - 项集长度：项集元素的个数，长度为k的项集称为k-项集
   - 示例：I={面包，牛奶，尿布，啤酒，茶}，|I|=5


**关联规则(Association Rule)**
+ 关联规则一般表示为X→Y的形式，左侧的项集X为先决条件，右侧项集Y为关联结果，用于表示数据内隐含的关联性。例如：假定关联规则“尿布→啤酒”成立，则表示购买了尿布的消费者往往也会购买啤酒这一商品。
+ 关联规则的有用性和可靠性，由规则的**支持度（support）、置信度（confidence）和提升度（lift）** 来度量。



**支持度(support)**
   - 定义：support(X→Y)=P(X,Y)，即项集{X,Y}出现的概率
   - 作用：衡量关联规则在"量"上的多少
   - 计算：示例中"尿布→啤酒"的支持度=4/10=40%，若minsup=10%，则该规则有效


> 这里的 minsup 就是 minimum support（最小支持度），是关联规则挖掘里一个非常核心的阈值参数。


**置信度(confidence)**
   - 定义：confidence(X→Y)=P(Y|X)=P(X,Y)/P(X)
   - 作用：衡量规则可靠性，需设置最小置信度阈值(mincon)
   - 计算：示例中"尿布→啤酒"的置信度=4/6=66.7%，若mincon=50%，则该规则可靠


**提升度(lift)**
   - 定义：lift(X→Y)=P(Y|X)/P(Y)=confidence(X→Y)/P(Y)
   - 作用：衡量规则可靠性，作为置信度的互补指标
   - 解释：lift=1表示X与Y相互独立，值越大(>1)表示关联性越强
   - 计算：示例中lift(尿布→啤酒)=1.33>1，说明规则可靠


关联规则的完整表示如下：

```
格式：规则[support=%；confidence=%]
示例："尿布→啤酒[support=40%；confidence=66.7%]"
```


### 关联规则挖掘的步骤

先找“经常一起出现的东西”（频繁项集），再从这些东西里挑出“方向可靠的规则”（强关联规则）。

- 第一步：找出所有频繁项集,
  - 扫描数据库，计算每个项集的支持度
  - 保留支持度≥minsupp的项集，称为频繁项集
- 第二步：由频繁项集产生强关联规则
  - 生成频繁项集X的所有非空子集
  - 对每个子集x⊂X，若confidence(x→X-x)≥mincon，则x→X-x是强关联规则




### 频繁项集的产生
+ 项集格结构
   - **格结构(lattice structure)** 表示所有可能的项集
   - 包含k个项的数据集产生2ᵏ-1个子集（不包括空集），称为**候选项集(candidate itemset)**
   - 示例：项集I={a,b,c,d,e}有31个候选项集


![alt text](image.png)


假设
+ 有 N 张小票（N 个顾客的交易）
+ 全部不同商品总数是 k
+ 想枚举所有非空组合：M = 2^k - 1
+ 每张小票里买的商品数不一样，记：
  + 第 i 张小票长度：|T_i|
  + 最大长度：s = max{|T_i|}, i=1,2,...,N
+ 对每个组合 C，检查所有小票 T_i，看 C 是T_i的子集是否成立。

如果使用普通枚举法，最坏的情况是时间复杂度是 O(N * M * s^2),而如果使用现代的**哈希查找**或者**双指针**，可以把时间复杂度降低到 O(N * M * s)。


然后，即使是O(N * M * s)，由于M中的数量是指数级增长的,例如有三十件商品，k=30 → $2^{30}$ 约 10 亿种组合,哪怕 s 很小、Hash 查询很快，也没法枚举。

所以关联规则挖掘才走到第一步，即“找出所有频繁项集”时，就会因为“候选项集过多”，导致无法继续。

因此需要想办法减少 M 的数量，这就是**频繁项集挖掘算法**的目标。
+ Apriori算法
+ FP-growth算法

## Apriori算法

### Apriori算法的频繁项集产生

Apriori算法是Agrawal和R. Srikant于1994年提出的，为布尔关联规则挖掘频繁项集的原创性算法。Apriori算法的核心是使用**候选项集**寻找频繁项集。

Apriori使用一种称为逐层搜索的迭代方法，k项集用于搜索（k+1）项集。首先，找出所有频繁1项集的集合L1，然后用L1生成候选2项集的集合C2，最后，通过探查候选2项集的集合来形成频繁2项集的集合L2。以此类推，使用L2寻找L3。如此迭代，直至不能找到频繁k项集为止。


**先验性质(Apriori property)**

核心：频繁项集的所有非空子集也一定是频繁项集。该先验性质可引申出两个结论：
- 结论1：若X为频繁项集，则X的所有子集都是频繁项集
- 结论2：若X为非频繁项集，则X的所有超集均为非频繁项集

![alt text](image-1.png)

作用是压缩搜索空间，提高效率。


利用先验性质，我们在使用频繁(k-1)项集的集合Lk-1寻找频繁k项集的集合Lk时分两个过程：**连接步**和**剪枝步**。


**寻找频繁k项集的过程**
- 连接步：Lₖ₋₁自连接产生候选k项集Cₖ，前提是两个项集有(k-2)个相同项
- 剪枝步：扫描事务集D，计算Cₖ中每个项集支持度计数，形成频繁k项集Lₖ
- 最小支持度计数：最小支持度阈值与事务总数的乘积



Apriori算法评价
- 空间复杂度：L₁为10⁴量级时，C₂可达10⁷量级
- 时间复杂度：每计算Cₖ需扫描一遍数据库
- 缺点：对海量数据，时空复杂度高



## FP-growth算法

在许多情况下，Apriori算法显著地压缩了候选项集的规模，并产生很好的性能。但是，该算法存在以下不足：

1. 可能产生大量频繁项集。例如，如果有104个频繁1项集，则Apriori算法需要产生多达107个候选2项集。
2. 可能需要重复地扫描整个数据库，通过模式匹配检查一个很大的候选集合。检查数据库中每个事务来确定候选项集支持度的开销很大。

FP-growth算法采取**分而治之**的思路：首先，将代表频繁项集的数据库压缩到一棵频繁模式树（Frequent Pattern tree，简称FP树）中，该树仍然保留项集的关联信息。然后，把这种压缩后的数据库划分成一组条件数据库（一种特殊类型的投影数据库），每个数据库关联一个频繁段或“模式段”，并分别挖掘每个条件数据库。对于每个“模式片段”，只需要考察与它相关联数据集。因此，随着被考察的模式的“增长”，这种方法可以显著地压缩被搜索的数据集的大小。由上可知，FP-growth算法包含两个步骤：
1. 构造FP树；
2. 在FP树上挖掘频繁项集。



### 构造FP树

1. **算法步骤**
   - 第一步：构造FP树
   - 第二步：在FP树上挖掘频繁项集

2. **FP树构造示例**
   - 步骤：
     - 确定所有项的集合I及支持度计数，丢弃非频繁项，按支持度降序排序
     - 对每个事务剔除非频繁项后，按排序结果重排
     - 构建FP树：从根节点null开始，按项顺序创建路径，共享前缀合并
     - 创建项头表：每项通过结点链指向树中位置

### 挖掘FP树
1. **挖掘过程**
   - 从长度为1的频繁模式开始，构造条件模式基
   - 构建条件FP树，递归挖掘
   - 模式增长：通过后缀模式与条件FP树产生的频繁模式连接实现

2. **挖掘步骤**
   - 逆序扫描项头表
   - 对每个频繁项，获取以其结尾的前缀路径
   - 更新前缀路径支持度计数，得到条件模式基
   - 构建条件FP树
   - 生成频繁项集：多条路径则继续迭代，一条路径则直接求频繁项集




## 其他关联规则算法

### 约束性关联规则
1. **相关概念及定义**
   - 基于项约束条件C的关联规则形如X≥Y，X⊂I，Y⊂I，X∩Y=Φ
   - 成立条件：
     1) 具有支持度s：≥s%记录包含X∪Y
     2) 具有置信度c：≥c%包含X的记录同时包含Y
     3) 满足项约束条件C
   - 约束条件C的DNF形式：d₁∨d₂∨...∨dₘ，其中dᵢ=aᵢ₁∧aᵢ₂∧...∧aᵢₘ

2. **相关算法及改进**
   - 早期算法：MultipleJoins、Recorder、Direct算法
   - 改进算法：ElcatA、AMMC、FICA、CSAR等，利用约束条件分类
   - 深入算法：DFTFH、VCM、MSEB等，使用FP-tree或概念格
   - 其他算法：基于二进制约束、权重和时序约束的算法

### 增量式关联规则
1. **相关概念及定义**
   - 更新问题情况：
     1) 数据库不变，最小支持度变化
     2) 支持度不变，添加事务集d₁
     3) 支持度不变，删除事务集d₂⊂D

2. **相关算法及改进**
   - 基于Apriori的算法：
     - FUP和FUP2：处理数据集减少
     - UWEP：提前剪枝策略
     - YAMI：处理多时间节点新数据
     - IUA和NEWIUA：处理支持度变化
   - 基于FP-growth的算法：
     - AFPIM：调整树结构
     - FIUA1和FIUA2：处理支持度和数据量变化
     - IFP-Growth：整合支持度和数据集变化
     - IACAI：提前缩减数据集

### 多层关联规则
1. **多层关联规则定义**
   - 概念层次树T表示项的概括关系
   - 若P到Q有弧，则P是Q的祖先，Q是P的子孙
   - 关系具有传递性

2. **挖掘步骤**
   - 第一步：挖掘所有频繁模式FP={X|X⊆I,support(X)≥minsup}
   - 第二步：产生强关联规则
     - 对每个频繁项集t，生成所有非空子集
     - 对每个子集s，若support(t)/support(s)≥minconf，则输出s⇒(t-s)
   - 第三步：删除不感兴趣的、冗余规则

3. **常用算法及改进**
   - 经典算法：
     - Cumulate：多层及跨层次挖掘，但仅在同一层考虑
     - ML-T2L1：自顶向下挖掘，不支持跨层次
   - 改进算法：
     - MLAR-FP：基于FP-growth，添加事务中所有祖先
     - Ada-FP：多支持度约束的多层多维挖掘
     - 其他：多支持度算法、加权算法、遗传算法改进、并行算法


